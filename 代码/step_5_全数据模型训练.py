"""
æ‰€å¾—ç»“æœé‡‡ç”¨çš„æœ€åä¸€æ¬¡ç²¾è°ƒæ‰€å¾—ç»“æœï¼Œä»¥F1å¾—åˆ†ä¸ºä¼˜å…ˆæŒ‡æ ‡

{
  "num_leaves": 11,
  "max_depth": 11,
  "subsample": 0.11769756360946987,
  "colsample_bytree": 0.29572538572787305,
  "scale_pos_weight": 1.7061180004294085,
  "min_child_samples": 75,
  "min_child_weight": 0.009613097955749644,
  "reg_alpha": 0.00314138443087681,
  "reg_lambda": 5.205819397783783,
  "threshold": 0.3329736384164349
  "n_estimators":528
  "boosting_type": "gbdt",
  "learning_rate": 0.05,

  "random_state": 42,
}
"""

import os
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from datetime import datetime
from lightgbm import LGBMClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.metrics import (
    roc_curve, auc,
    recall_score, f1_score,
    confusion_matrix
)
from sklearn.preprocessing import LabelEncoder

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. è·¯å¾„è®¾ç½®
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
file_path = r"E:\software\Jetbrains\Python Project\25_1__ML_learn\é¡¹ç›®ç»ƒä¹ _25_4_11_Health Insurance Cross Sell Prediction ğŸ  ğŸ¥\æ•°æ®æº\archive\train_å¤„ç†åæ•°æ®.csv"
output_base_path = r"E:\software\Jetbrains\Python Project\25_1__ML_learn\é¡¹ç›®ç»ƒä¹ _25_4_11_Health Insurance Cross Sell Prediction ğŸ  ğŸ¥\ç»“æœä¸€è§ˆ\step_5_æœ€ç»ˆæ¨¡å‹"
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
out_dir = os.path.join(output_base_path, f"final_model_fixed_params_{timestamp}")
os.makedirs(out_dir, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ç›´æ¥è½½å…¥å›ºå®šè¶…å‚æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fixed_params = {
    "boosting_type": "gbdt",
    "learning_rate": 0.05,
    "n_estimators": 528,
    "num_leaves": 11,
    "max_depth": 11,
    "subsample": 0.11769756360946987,
    "colsample_bytree": 0.29572538572787305,
    "scale_pos_weight": 1.7061180004294085,
    "min_child_samples": 75,
    "min_child_weight": 0.009613097955749644,
    "reg_alpha": 0.00314138443087681,
    "reg_lambda": 5.205819397783783,
    "random_state": 42,
    "n_jobs": 3,
    "min_split_gain": 0.001,
}
threshold = 0.3329736384164349

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. è¯»å–å¹¶ç¼–ç æ•°æ®ï¼ˆåŒæ—¶æ„å»ºå¹¶ä¿å­˜ LabelEncoder å®ä¾‹ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.read_csv(file_path)
y  = df["Response"]
X  = df.drop(columns=["Response", "id"], errors="ignore")

# 1) æ§‹å»ºä¸€å€‹ dict ä¾†ä¿å­˜æ‰€æœ‰çš„ LabelEncoder
label_encoders = {}
# è‡ªå‹•åµæ¸¬æ‰€æœ‰ object æ¬„ä½ï¼Œé€æ¬„ fit ä¸€å€‹ LabelEncoder
for col in X.select_dtypes(include="object"):
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))
    label_encoders[col] = le

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. 5 æŠ˜ CV è¯„ä¼°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

tprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)
recalls = []
f1s = []

with open(os.path.join(out_dir, "metrics.txt"), "w", encoding="utf-8") as log:
    log.write(f"Fixed params evaluation ({timestamp})\n\n")

    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), 1):
        X_tr, X_val = X.iloc[train_idx], X.iloc[valid_idx]
        y_tr, y_val = y.iloc[train_idx], y.iloc[valid_idx]

        model = LGBMClassifier(**fixed_params)
        model.fit(X_tr, y_tr)

        prob = model.predict_proba(X_val)[:, 1]
        pred = (prob > threshold).astype(int)

        r = recall_score(y_val, pred)
        f = f1_score(y_val, pred)
        fpr, tpr, _ = roc_curve(y_val, prob)
        roc_auc = auc(fpr, tpr)

        recalls.append(r)
        f1s.append(f)
        aucs.append(roc_auc)

        interp_tpr = np.interp(mean_fpr, fpr, tpr)
        interp_tpr[0] = 0.0
        tprs.append(interp_tpr)

        line = f"Fold {fold}: Recall={r:.4f}, F1={f:.4f}, AUC={roc_auc:.4f}\n"
        print(line, end="")
        log.write(line)

    # å¹³å‡æŒ‡æ ‡
    mean_recall = np.mean(recalls)
    mean_f1     = np.mean(f1s)
    mean_auc_cv = np.mean(aucs)
    summary = (
        f"\nMean Recall = {mean_recall:.4f} Â± {np.std(recalls):.4f}\n"
        f"Mean F1     = {mean_f1:.4f} Â± {np.std(f1s):.4f}\n"
        f"Mean AUC    = {mean_auc_cv:.4f} Â± {np.std(aucs):.4f}\n"
    )
    print(summary)
    log.write(summary)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ç»˜åˆ¶å¹¶ä¿å­˜å¹³å‡ ROC æ›²çº¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
plt.figure(figsize=(8, 6))
plt.plot([0,1], [0,1], "--", color="gray")
mean_tpr = np.mean(tprs, axis=0)
mean_tpr[-1] = 1.0
plt.plot(mean_fpr, mean_tpr,
         label=f"Mean ROC (AUC={mean_auc_cv:.4f})", lw=2)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (5-fold CV)")
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
path = os.path.join(out_dir, "roc_curve_cv.png")
plt.savefig(path); plt.close()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. æ··æ·†çŸ©é˜µï¼ˆcross-val predictï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
probs_all = cross_val_predict(
    LGBMClassifier(**fixed_params), X, y,
    cv=kf, method="predict_proba"
)[:,1]
preds_all = (probs_all > threshold).astype(int)

cm = confusion_matrix(y, preds_all)
plt.figure(figsize=(5, 5))
plt.imshow(cm, cmap="Blues", interpolation="nearest")
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, cm[i,j],
                 ha="center", va="center",
                 color="white" if cm[i,j]>cm.max()/2 else "black")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (CV)")
plt.tight_layout()
path = os.path.join(out_dir, "confusion_matrix.png")
plt.savefig(path); plt.close()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. å…¨é‡è®­ç»ƒã€ç‰¹å¾é‡è¦æ€§ & æ¨¡å‹ä¿å­˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
final_model = LGBMClassifier(**fixed_params)
final_model.fit(X, y)

# ç‰¹å¾é‡è¦æ€§
imp = final_model.feature_importances_
plt.figure(figsize=(10, 6))
plt.barh(X.columns, imp)
plt.xlabel("Importance")
plt.title("Feature Importances (Full Model)")
plt.tight_layout()
path = os.path.join(out_dir, "feature_importance_full.png")
plt.savefig(path); plt.close()

# ä¿å­˜æ¨¡å‹
joblib.dump(final_model, os.path.join(out_dir, "final_model.joblib"))

# **ä¿å­˜ LabelEncoder å­—å…¸**
encoder_path = os.path.join(out_dir, "label_encoders.joblib")
joblib.dump(label_encoders, encoder_path)
print(f"âœ… ç·¨ç¢¼å™¨å·²ä¿å­˜ï¼š{encoder_path}")

print("\nâœ… å…¨æµç¨‹å®Œæˆï¼Œæ‰€æœ‰ç»“æœä¿å­˜åœ¨ï¼š", out_dir)

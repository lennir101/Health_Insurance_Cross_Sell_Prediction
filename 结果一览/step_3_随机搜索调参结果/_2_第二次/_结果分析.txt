# ✅ 参数空间定义（基于调整后区间）
param_space = {
    "threshold": [0.1, 0.15, 0.2, 0.25, 0.3, 0.33],
    "scale_pos_weight": [1.4, 1.6, 1.8, 2.0, 2.2],
    "num_leaves": list(range(3, 9)),  # 3到8，保持持平区间
    "max_depth": list(range(3, 23, 2)),  # 3到22，步长2，更细
    "subsample": [0.1, 0.15, 0.2, 0.3, 0.4, 0.42],
    "colsample_bytree": [0.35, 0.45, 0.55, 0.6, 0.65],
    "min_child_samples": [50, 60, 70, 80, 90, 100, 110, 120, 130],
    "min_child_weight": [0, 0.001, 0.005, 0.01, 0.02],
    "reg_alpha": [0, 0.001, 0.005],  # 超小alpha确认必要性
    "reg_lambda": [0.1, 0.3, 0.5, 0.7, 1.0],
}


colsample_bytree vs F1-score
仍未找到最佳区间，0.35时最高，越大F1分数越小，需要查看0.35左侧的区间
下一步调整为0.1--0.4

max_depth vs F1-score
两次测试结果存在一定差异，但趋势相一致，拥有9--11、 17两个峰值
区间大小暂且不要改变，继续细分区间


min_child_samples vs F1-score
与上次测试截然相反，130表现最佳，110--130区间无法满足
尝试在50-75以及110--140内测试，应该测试50--141内，以5为步长的区间

min_child_weight vs F1-score
第一次第二次结果一致
需要细分到0～0.002测试

num_leaves vs F1-score
第一次3--8内基本持平，第二次集中表现为7为最佳，差异原因未知
暂且不改变区间

reg_alpha vs F1-score
两次测试结果并不矛盾，0附近较好，中、大值下降
保持 0～0.005 微调

reg_lambda vs F1-score
两次测试结果并不矛盾，高于0.5后开始好转，有拐点但趋势微弱
扩大探索 0.5～2.0

scale_pos_weight vs F1-score
两次测试结果有矛盾，第一次最佳值为2.0，第二次判定为1.4左侧，原因未知
1.4的左区间

subsample vs F1-score
两次测试结果有矛盾，暂且以第二次测试结果为准
集中测试0.2附近的区间

threshold vs F1-score
结果并不矛盾，集中测试0.3附近的区间
0.25--0.35




为什么 num_leaves 两次测试结果大相径庭？
原因总结：
num_leaves控制了一棵树最大叶子节点数，直接关联模型复杂度。
第一次搜索范围比较小（2～8），且配合的是"偏保守"的采样率、正则化，因此小叶子效果不错；
第二次搜索，subsample、colsample_bytree都更小了，意味着每棵树更稀疏了，**所以可以承受更多叶子（较大num_leaves）**而不会过拟合。
✅本质：num_leaves的最佳取值高度依赖于subsample、colsample_bytree与正则项的配合。


综合观察：
reg_alpha（L1正则）：两次都是越小越好，表明当前模型不太需要剪枝特征权重，对L1惩罚不敏感。
reg_lambda（L2正则）：第一次变化小，第二次在 0.5之后有所提升，说明更高复杂度的模型（更多num_leaves、更深max_depth）需要一定的L2正则来防止过拟合。
✅本质总结：
alpha可以直接设小（甚至设0）；
lambda建议继续调优，比如0.5～2.0区间找局部最优。


为什么 scale_pos_weight 两次结论差异大？
原因总结：
scale_pos_weight是调整正负样本平衡的权重，适用于极度不平衡数据。
第一次大致样本结构偏标准（整体scale_pos_weight=2左右最佳），
第二次因为subsample、colsample下降，正负样本比例在训练中出现了新的偏差，导致更小scale_pos_weight反而更好，即靠模型内部自适应即可，不需要人为强行加权。
✅本质：
scale_pos_weight 的最佳值依赖于其他参数影响下，正负样本在子集中的分布情况。


第一次采样点范围偏大（0.4～0.6），第二次直接探到0.1～0.4了。
subsample影响树的训练样本数量，子采样小，可以有效降低过拟合，但也可能降低模型表达力。
如果其他参数（比如max_depth、num_leaves）配置偏简单，subsample太低会欠拟合；但如果其他参数复杂度上来了（第二次明显更多深度/叶子），小subsample反而可以带来更好性能。
✅本质：
subsample 的最佳值依赖于整体模型复杂度：模型复杂，subsample可以小；模型简单，subsample不能太小。





针对你的提问逐条回答
① max_depth两次峰值不同：
第一次峰值在6和15，第二次在11和17。

原因是：搜索区间的不同、采样点不同，导致局部最优峰值有所漂移。

但是注意到趋势是一致的：中等偏高（10～15）附近效果较好。

结论：下一步合理的区间是 8～18，再精细一些，用步长2或1。

② num_leaves两次结果不同：
第一次：3～8持平，第二次集中在7最好。

可能原因：

第一次范围过大，导致“低叶子数”均分；

第二次区间收窄后，7附近参数组合更多地出现了配套好的其他超参数（比如min_child_weight、subsample、colsample_bytree一起优化），所以7显得更好。

结论：num_leaves 锁定5～9继续细分即可。

③ 正则化参数总结（reg_alpha 和 reg_lambda）：
reg_alpha（L1）：0附近最佳，值大于0.01后迅速下降；

reg_lambda（L2）：约0.5以上逐渐变好，且1.0较佳。

结论：alpha继续在0～0.01内细调，lambda应扩大在0.5～2.0继续细化。

④ scale_pos_weight两次结果差异：
第一次：2.0最佳，第二次：1.4最佳。

原因：

随机采样差异；

与其他参数组合搭配产生了不同的局部最优；

本质上说明scale_pos_weight在1.2～2.0之间变化，未来需要更细致搜索。

结论：下一步调整为1.2～2.0，步长0.2更稳妥。

⑤ subsample趋势差异原因：
第一次：0.4处最佳；

第二次：0.2处最佳；

原因：

第二次采样范围扩大，且subsample低值时，搭配了更强的正则化（reg_lambda=1.0），所以更抗过拟合；

第一次正则化弱，subsample高一些才能稳定。

结论：subsample应继续在0.1～0.3探索。

⑥ 总结为什么趋势变化大：
采样不同 + 参数空间变化 + 参数交互效应 + 局部最优漂移；

特别是LightGBM超参数之间高度非线性关联，一点点变化导致整体模型搜索曲面变形；

不是你设置错误，而是这就是机器学习调参本身复杂性的必然现象。
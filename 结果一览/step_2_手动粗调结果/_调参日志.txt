样本不平衡，需要优先锁定scale_pos_weight的范围，确保后面训练的正确性
发现其结果与预测的大相径庭，一般而言，该参数应当包含经验值 负类样本数/正类样本数，本项目里大约为7
然而根据 结果①、② 可以发现以AUC为指标，scale_pos_weight最佳取值为默认值1.0，随着数值增大，auc的值反而下降，且其他指标无限趋近于零
这说明模型无法正常分辨认作为极少数的正类标签样本，倾向于将所有样本都预测为负类，导致模型的泛化能力较差

这个和 分类阈值 有关联：
LightGBM 训练的是“概率排序器”，即每个样本是正类的 预测概率，需要用分类阈值把它转成分类器。
该模型本质上是输出各个样本为正类的概率，而分类阈值则是根据概率来判断样本属于正类还是负类
分类阈值与评判指标存在关系，比如AUC完全依赖于正类的预测概率是否大于负类的预测概率，即只与排序有关，与阈值无关
而F1分数与Recall二者，依赖分类阈值，均不考虑排序，即F1分数与Recall的效果会受到分类阈值的影响
这使得在样本标签极度不平衡的数据集里，即便所有样本都预测为负类，只要排序正确，AUC 高，全是负类 →正类都没抓住→ Recall = 0，F1 = 0

总结：
现在的现象背后是以下逻辑链条：
✅ scale_pos_weight 越大	正类惩罚越重，模型越保守
✅ 模型越保守	所有预测概率越低（就算它知道哪个是正类）
✅ 用默认 0.5 做分类	全部预测为负类 → Recall = 0, F1 = 0
✅ 但是排序没变	所以 AUC 还是高
✅ 所以 scale_pos_weight 不等于越大越好	要看你的评价指标是否需要实际“命中”正类

解决方案：
需要优先调整分类阈值，锁定分类阈值后再进行手动粗调
最佳阈值锁定为0.33，暂且不动，然后再调整 scale_pos_weight


手动粗调总结：
阈值区间为0.3--0.4，最佳为0.33

scale_pos_weight：
综合指标来看，保证recall以及其他指标的情况下，表现良好的区间为1.6--2.6，最佳的取值为2.0

boosting_type：gbdt为最佳

num_leaves：1--8  最佳为6

max_depth：1-20内变化不大，最佳为5

subsample：调整后发现取值不影响指标，原因大概为应用的样本量较少，且使用了早停参数,暂且锁定为0.5

colsample_bytree：区间内指标变化不大，最优为0.6--0.75，最优为0.65

min_child_samples：最佳为105，范围为75--135



随机搜索调参：
原本想要使用网格搜索，奈何参数数目比较多，加上区间和k折交叉验证，耗时爆炸，八十一万组参数组合，还要五折交叉验证，故改为随机搜索

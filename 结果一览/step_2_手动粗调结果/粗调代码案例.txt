import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder
from datetime import datetime
import os

# âœ… è·¯å¾„è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ å®é™…è·¯å¾„ï¼‰
file_path = r"E:\software\Jetbrains\Python Project\25_1__ML_learn\é¡¹ç›®ç»ƒä¹ _25_4_11_Health Insurance Cross Sell Prediction ğŸ  ğŸ¥\æ•°æ®æº\archive\train_å¤„ç†åæ•°æ®.csv"
output_path = r"E:\software\Jetbrains\Python Project\25_1__ML_learn\é¡¹ç›®ç»ƒä¹ _25_4_11_Health Insurance Cross Sell Prediction ğŸ  ğŸ¥\ç»“æœä¸€è§ˆ\step_2_æ‰‹åŠ¨ç²—è°ƒç»“æœ"

os.makedirs(output_path, exist_ok=True)

# âœ… è¯»å–æ•°æ®
df = pd.read_csv(file_path)
y = df["Response"]
X = df.drop(columns=["Response", "id"], errors="ignore")

# âœ… LabelEncoder ç¼–ç ç±»åˆ«ç‰¹å¾
categorical_cols = X.select_dtypes(include='object').columns
le = LabelEncoder()
for col in categorical_cols:
    X[col] = le.fit_transform(X[col])

# âœ… ä½¿ç”¨ 10% æ•°æ®
X_sample, _, y_sample, _ = train_test_split(X, y, train_size=0.1, stratify=y, random_state=42)

# âœ… å›ºå®šæœ€ä½³é˜ˆå€¼
fixed_best_threshold = 0.33

# âœ… è®¾ç½® scale_pos_weight æµ‹è¯•èŒƒå›´
scale_weights = np.round(np.arange(0.5, 10.01, 0.25), 2)
f1_scores, recalls, precisions, aucs, tree_counts = [], [], [], [], []

# âœ… å›ºå®šè®­ç»ƒé›†åˆ’åˆ†
X_train, X_valid, y_train, y_valid = train_test_split(X_sample, y_sample, test_size=0.3, stratify=y_sample, random_state=42)

# âœ… éå† scale_pos_weight
for sw in scale_weights:
    model = LGBMClassifier(
        num_leaves=31,
        learning_rate=0.05,
        n_estimators=1000,
        early_stopping_rounds=30,
        scale_pos_weight=sw,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], callbacks=[])
    y_prob = model.predict_proba(X_valid)[:, 1]
    y_pred = (y_prob > fixed_best_threshold).astype(int)

    f1_scores.append(f1_score(y_valid, y_pred))
    recalls.append(recall_score(y_valid, y_pred))
    precisions.append(precision_score(y_valid, y_pred))
    aucs.append(roc_auc_score(y_valid, y_prob))
    tree_counts.append(model.best_iteration_)

# âœ… æ‰¾åˆ°æœ€ä½³ F1 å‚æ•°
best_idx = np.argmax(f1_scores)
best_weight = scale_weights[best_idx]

# âœ… æ—¶é—´æˆ³
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# âœ… ç»˜å›¾
plt.figure(figsize=(10, 6))
plt.plot(scale_weights, f1_scores, label="F1-score", marker='o')
plt.plot(scale_weights, recalls, label="Recall", linestyle='--')
plt.plot(scale_weights, precisions, label="Precision", linestyle='-.')
plt.plot(scale_weights, aucs, label="AUC", linestyle=':', marker='^')
plt.xlabel("scale_pos_weight")
plt.ylabel("Score")
plt.title("scale_pos_weight vs F1 / Recall / Precision / AUC")
plt.grid()
plt.legend()
plt.savefig(os.path.join(output_path, f"scale_pos_weight_all_metrics_{timestamp}.png"))
plt.close()

# âœ… ä¿å­˜ CSV è¡¨æ ¼
results_df = pd.DataFrame({
    "scale_pos_weight": scale_weights,
    "F1_score": f1_scores,
    "Recall": recalls,
    "Precision": precisions,
    "AUC": aucs,
    "Best_Iteration": tree_counts
})
csv_path = os.path.join(output_path, f"scale_pos_weight_metrics_{timestamp}.csv")
results_df.to_csv(csv_path, index=False, encoding="utf-8-sig")

# âœ… ä¿å­˜ TXT æ—¥å¿—
log_path = os.path.join(output_path, f"scale_pos_weight_best_log_{timestamp}.txt")
with open(log_path, "w", encoding="utf-8") as f:
    f.write("æœ€ä½³ scale_pos_weight æœç´¢æŠ¥å‘Šï¼ˆå« AUCï¼Œå›ºå®šé˜ˆå€¼ï¼‰\n")
    f.write(f"æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    f.write(f"å›ºå®šåˆ†ç±»é˜ˆå€¼ï¼š{fixed_best_threshold:.2f}\n")
    f.write(f"æœ€ä½³ scale_pos_weightï¼š{best_weight}\n")
    f.write(f"F1-scoreï¼š{f1_scores[best_idx]:.4f}\n")
    f.write(f"Recallï¼š{recalls[best_idx]:.4f}\n")
    f.write(f"Precisionï¼š{precisions[best_idx]:.4f}\n")
    f.write(f"AUCï¼š{aucs[best_idx]:.4f}\n")
    f.write(f"Best Iterationï¼š{int(tree_counts[best_idx])}\n")
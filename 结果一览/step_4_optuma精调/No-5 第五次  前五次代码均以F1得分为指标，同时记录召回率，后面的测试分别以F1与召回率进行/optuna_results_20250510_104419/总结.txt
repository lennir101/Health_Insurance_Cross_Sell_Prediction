colsample_bytree   稳定 饱和  集中于0.27--0.35
    最佳参数均集中于0.27--0.35，将右侧区间进一步缩小为0.4

max_depth   大抵集中于15--24，但是纵坐标的角度来看比较分散，红色点群更为稳定集中，影响不大；
    区间暂且不变

min_child_samples    稳定集中于55--95    暂且修改为50--100

min_child_weight      区间暂且不变

num_leaves   大抵都在高数值区间，   区间修改为8--15

reg_alpha   集中稳定与0.0026--0.0030  区间暂时不变

reg_lambda    显著集中于2--6  右区间修改为8

scale_pos_weight  出现了显著的极值，极值点位于2.25左右,但此时可发现F1迎来一定程度的降低
    先测试2.25附近的效果如何，查看F1参数下降的趋势如何
    如果与前面参数对比而言下降相当严重，则该参数以本次测试（第五次）的结果为准↓
    如若结果理想，F1参数下降不大，可尝试使用2.25附近的结果
    如若结果不佳，F1参数下降太多，结合前面的图像，预估大致的最优区间处于1.55--1.7之间，保守起见，将下一步的区间修改为1.4--1.8

subsample    多个峰值区间     区间暂且不变

threshold     集中于0.30--0.3      下一步将区间修改为0.28--0.36
    趋势随着数值变高而变低 该趋势与本参数含义有关，threshold越高，模型输出的正例概率越高，才能被判定为正例，反之，则判定为负例。


"""
所得结果采用的第五次optuma所得结果，以F1得分为优先指标
{
  "num_leaves": 12,
  "max_depth": 13,
  "subsample": 0.21050946109159988,
  "colsample_bytree": 0.3191743427622317,
  "scale_pos_weight": 1.5508083876797971,
  "min_child_samples": 84,
  "min_child_weight": 0.011564503021358441,
  "reg_alpha": 0.002854671256715976,
  "reg_lambda": 3.779690209331303,
  "threshold": 0.3177598781532248,
  "n_estimators":538.2
}


以此为准，下一次调整为：
# ✅ optuna目标函数（更新后的参数区间）
def objective(trial):
    params = {
        "boosting_type": "gbdt",
        "learning_rate": 0.05,
        "n_estimators": 1000,
        "num_leaves": trial.suggest_int("num_leaves", 11, 14),
        "max_depth": trial.suggest_int("max_depth", 11, 16),
        "subsample": trial.suggest_float("subsample", 0.1, 0.25),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.29, 0.33),
        "scale_pos_weight": trial.suggest_float("scale_pos_weight", 1.45, 1.75),
        "min_child_samples": trial.suggest_int("min_child_samples", 50, 100),
        "min_child_weight": trial.suggest_float("min_child_weight", 0.0008, 0.015),
        "reg_alpha": trial.suggest_float("reg_alpha", 0.0026, 0.003),
        "reg_lambda": trial.suggest_float("reg_lambda", 0.5, 6.0),

        "random_state": 42,
        "n_jobs": 3,
        "min_split_gain": 0.001,
    }
"""

